{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, time\nimport numpy as np\nimport random\nrandom.seed(42)\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n\nimport torch\ntorch.manual_seed(42)\nfrom torch import nn\nfrom torch.optim import SGD, Adam\nfrom torch.utils.data import DataLoader, RandomSampler\nfrom torch.utils.data.dataset import Dataset\nfrom torchvision.models import resnet\nfrom torchvision import transforms, datasets, models\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nprint('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-09-04T10:39:56.863225Z","iopub.execute_input":"2023-09-04T10:39:56.863737Z","iopub.status.idle":"2023-09-04T10:39:59.038664Z","shell.execute_reply.started":"2023-09-04T10:39:56.863699Z","shell.execute_reply":"2023-09-04T10:39:59.037446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_transform_images(images_path, presplit, train_split, test_split, val_split, batch_size, threads, mean, std):\n    train_transform = transforms.Compose([\n                                         #transforms.RandomRotation(degrees=15),\n                                         #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n                                         #transforms.RandomResizedCrop((224,224)),\n                                         transforms.Resize((224,224)),\n                                         transforms.RandomHorizontalFlip(),\n                                         transforms.ToTensor(),\n                                         transforms.Normalize(torch.Tensor(mean),\n                                                              torch.Tensor(std))])\n\n    test_transform = transforms.Compose([\n                                        transforms.Resize((224,224)),\n                                        #transforms.CenterCrop((224,224)),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(torch.Tensor(mean),\n                                                             torch.Tensor(std))])\n\n    val_transform = transforms.Compose([\n                                       transforms.Resize((224,224)),\n                                       #transforms.CenterCrop((224,224)),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize(torch.Tensor(mean),\n                                                            torch.Tensor(std))])\n\n    if presplit:\n        try:\n            training_set = datasets.ImageFolder(root=images_path+'/train', transform=train_transform)\n            validation_set = datasets.ImageFolder(root=images_path+'/val', transform=val_transform)\n        except FileNotFoundError:\n            raise Exception('Not presplit into Training and Validation sets')\n        try:\n            testing_set = datasets.ImageFolder(root=images_path+'/test', transform=test_transform)\n        except:\n            testing_set = validation_set\n        dataset = training_set\n    else:\n        dataset = datasets.ImageFolder(root=images_path, transform=train_transform)\n        train_size = int(train_split * len(dataset))\n        test_size = int(test_split * len(dataset))\n        val_size = len(dataset) - train_size - test_size\n        training_set, testing_set, validation_set = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n    \n    training_set_loader = DataLoader(training_set, batch_size=batch_size, num_workers=threads, shuffle=True)\n    validation_set_loader = DataLoader(validation_set, batch_size=batch_size, num_workers=threads, shuffle=True)\n    testing_set_loader = DataLoader(testing_set, batch_size=batch_size, num_workers=threads, shuffle=False)\n\n    return training_set_loader, testing_set_loader, validation_set_loader, dataset, training_set, testing_set, validation_set\n\ndef load_network(net_model, net_name, dropout_ratio, class_names, unfrozen_layers):\n    for name, child in net_model.named_children():\n        if name in unfrozen_layers:\n            print(name + ' is unfrozen')\n            for param in child.parameters():\n                param.requires_grad = True\n        else:\n            print(name + ' is frozen')\n            for param in child.parameters():\n                param.requires_grad = False\n\n    if net_name.startswith('resnet'):\n        num_ftrs = net_model.fc.in_features\n        net_model.fc = nn.Sequential(nn.Linear(num_ftrs, 256),\n                                     nn.ReLU(),\n                                     nn.Dropout(p=dropout_ratio),\n                                     nn.Linear(256, len(class_names)))\n\n    elif net_name.startswith('vgg'):\n        num_ftrs = net_model.classifier[6].in_features\n        net_model.classifier[6] = nn.Sequential(nn.Linear(num_ftrs, 256),\n                                                nn.ReLU(),\n                                                nn.Dropout(p=dropout_ratio),\n                                                nn.Linear(256, len(class_names)))\n    display(net_model)\n    \n    total_params = sum(param.numel() for param in net_model.parameters())\n    print(f'{total_params:,} total parameters')\n\n    total_trainable_params = sum(param.numel() for param in net_model.parameters() if param.requires_grad)\n    print(f'{total_trainable_params:,} training parameters')\n    \n    return net_model","metadata":{"execution":{"iopub.status.busy":"2023-09-04T10:39:59.042560Z","iopub.execute_input":"2023-09-04T10:39:59.043599Z","iopub.status.idle":"2023-09-04T10:39:59.086381Z","shell.execute_reply.started":"2023-09-04T10:39:59.043545Z","shell.execute_reply":"2023-09-04T10:39:59.085269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images_per_class(images_path, mode, title):\n    data_folder = images_path+'/'+mode+'/'\n    item_dict = {root.split('/')[-1]: len(files) for root, _, files in os.walk(data_folder)}\n   \n    plt.figure(figsize=(20,8))\n    plt.bar(list(item_dict.keys())[1:], list(item_dict.values())[1:], color='g')\n    plt.title(title)\n    plt.xticks(rotation=90)\n    plt.xlabel('Class')\n    plt.ylabel('Number of Images')\n    plt.show()\n\ndef plot_grid_images(training_set, batch_size, class_names, mean, std, rows=3, columns=3, size=14):\n    sampler = RandomSampler(training_set, num_samples=batch_size, replacement=True)\n    train_loader = DataLoader(training_set, sampler=sampler, shuffle=False, batch_size=batch_size, num_workers=0)\n    \n    dataiter = iter(train_loader)\n    images, labels = dataiter.next()\n\n    plt.figure(figsize=(size,size))\n    for i in range(rows*columns):\n        plt.subplot(rows, columns, i+1)\n        plt.title(class_names[labels.numpy()[i]])\n        img = images[i].permute(1,2,0)\n        img = torch.tensor(std)*img + torch.tensor(mean)\n        plt.axis('off')\n        plt.imshow(img, interpolation='none')\n        plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-09-04T10:39:59.088108Z","iopub.execute_input":"2023-09-04T10:39:59.088762Z","iopub.status.idle":"2023-09-04T10:39:59.113707Z","shell.execute_reply.started":"2023-09-04T10:39:59.088720Z","shell.execute_reply":"2023-09-04T10:39:59.112210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def train_model(results_path, model_name, model, train_loader, val_loader, lr, epoch, momentum, weight_decay, patience, n_epochs_stop):\n    \"\"\"\n    \"\"\"\n    #if not os.path.exists(results_path+'/'+model_name):\n    #    os.makedirs(results_path+'/'+model_name)\n        \n    criterion = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr=lr)\n    #optimizer = SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n    scheduler = ReduceLROnPlateau(optimizer, patience=patience, factor=0.1, verbose=True)\n    \n    loaders = {'train': train_loader, 'val': val_loader}\n    losses = {'train': [], 'val': []}\n    accuracies = {'train': [], 'val': []}\n    \n    y_testing = []\n    preds = []\n    \n    min_val_loss = np.Inf\n    epochs_no_improv = 0\n    \n    if torch.cuda.is_available():\n        if torch.cuda.device_count() > 1:\n            model = nn.DataParallel(model)\n        print(f'Using {torch.cuda.device_count()} GPUs')\n        model.cuda()\n    else:\n        print('Using CPU')\n    \n    start = time.time()\n    max = 0\n    for epoch in range(epochs):\n        for mode in ['train', 'val']:\n            if mode == 'train':\n                model.train()\n            if mode == 'val':\n                model.eval()\n            \n            epoch_loss = 0\n            epoch_acc = 0\n            samples = 0\n\n            for i, (inputs, targets) in enumerate(loaders[mode]):\n                if torch.cuda.is_available():\n                    inputs = inputs.cuda()\n                    targets = targets.cuda()\n                \n                optimizer.zero_grad()\n                output = model(inputs)\n                loss = criterion(output, targets)\n                \n                if mode == 'train':\n                    loss.backward()\n                    optimizer.step()\n                else:\n                    y_testing.extend(targets.data.tolist())\n                    preds.extend(output.max(1)[1].tolist())\n                \n                if torch.cuda.is_available():\n                    acc = accuracy_score(targets.data.cuda().cpu().numpy(), output.max(1)[1].cuda().cpu().numpy())\n                else:\n                    acc = accuracy_score(targets.data, output.max(1)[1])\n\n                epoch_loss += loss.data.item()*inputs.shape[0]\n                epoch_acc += acc*inputs.shape[0]\n                samples += inputs.shape[0]\n                \n                if i % (len(loaders[mode])//5) == 0:\n                    print(f'[{mode}] Epoch {epoch+1}/{epochs} Iteration {i+1}/{len(loaders[mode])} Loss: {epoch_loss/samples:0.2f} Accuracy: {epoch_acc/samples:0.2f}')\n            \n            epoch_loss /= samples\n            epoch_acc /= samples\n            losses[mode].append(epoch_loss)\n            accuracies[mode].append(epoch_acc)\n            \n            print(f'[{mode}] Epoch {epoch+1}/{epochs} Iteration {i+1}/{len(loaders[mode])} Loss: {epoch_loss:0.2f} Accuracy: {epoch_acc:0.2f}')\n            \n            if mode == 'val':\n                scheduler.step(epoch_loss)\n        \n        if mode == 'val':\n            if epoch_loss < min_val_loss:\n                torch.save(model.state_dict(), '/kaggle/working/'+str(model_name)+'.pth')\n                epochs_no_improv = 0\n                min_val_loss = epoch_loss\n            else:\n                epochs_no_improv += 1\n                print(f'Epochs with no improvement {epochs_no_improv}')\n                if epochs_no_improv == n_epochs_stop:\n                    print('Early stopping!')\n                    return model, (losses, accuracies), y_testing, preds\n                model.load_state_dict(torch.load('/kaggle/working/'+str(model_name)+'.pth'))\n                \n    print(f'Training time: {time.time()-start} min.')\n    return model, (losses, accuracies), y_testing, preds\n\ndef test_model(model_name, model, test_loader):\n    model.load_state_dict(torch.load('/kaggle/working/'+str(model_name)+'.pth'))\n\n    if torch.cuda.is_available():\n        model.cuda()\n    model.eval()\n    \n    preds = []\n    trues = []\n    \n    for i, (inputs, targets) in enumerate(test_loader):\n        if torch.cuda.is_available():\n            inputs = inputs.cuda()\n            pred = model(inputs).data.cuda().cpu().numpy().copy()\n        else:\n            pred = model(inputs).data.numpy().copy()\n            \n        true = targets.numpy().copy()\n        preds.append(pred)\n        trues.append(true)\n\n        if i % (len(test_loader)//5) == 0:\n            print(f'Iteration {i+1}/{len(test_loader)}')\n    return np.concatenate(preds), np.concatenate(trues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_confusion_matrix(results_path, model_name, y_true, preds, class_names, annot, figsize=(9,7), fontsize=14):\n    #if not os.path.exists(results_path+'/'+model_name):\n    #    os.makedirs(results_path+'/'+model_name)\n\n    acc = accuracy_score(y_true, preds.argmax(1))\n    score = f1_score(y_true, preds.argmax(1), average='micro')\n    cm = confusion_matrix(y_true, preds.argmax(1))\n    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n    np.set_printoptions(precision=2)\n    \n    string1 = 'Confusion Matrix for Testing Data'\n    string2 = f'Accuracy is {acc:0.3f}; F1-score is {score:0.3f}'\n    title_str = string1.center(len(string2))+'\\n'+string2\n\n    plt.figure(figsize=figsize)\n    sns.set(font_scale=1.2)\n    sns.heatmap(df_cm, annot=annot, annot_kws={'size': fontsize}, fmt='d')\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.title(title_str)\n    \n    #plt.savefig(str(results_path)+'/'+str(model_name)+'/'+str(model_name)+'_conf_mat.png')\n    \ndef plot_logs_classification(results_path, model_name, logs):\n    \"\"\"\n    \"\"\"\n    #if not os.path.exists(results_path+'/'+model_name):\n    #    os.makedirs(results_path+'/'+model_name)\n        \n    training_losses, training_accuracies, test_losses, test_accuracies = \\\n        logs[0]['train'], logs[1]['train'], logs[0]['val'], logs[1]['val']\n    \n    plt.figure(figsize=(18,6))\n    plt.subplot(121)\n    plt.plot(training_losses)\n    plt.plot(test_losses)\n    plt.legend(['Training Loss', 'Validation Loss'])\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.grid()\n    \n    plt.subplot(122)\n    plt.plot(training_accuracies)\n    plt.plot(test_accuracies)\n    plt.legend(['Training Accuracy', 'Validation Accuracy'])\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.grid()\n    \n    #plt.savefig(str(results_path)+'/'+str(model_name)+'/'+str(model_name)+'_graph.png')","metadata":{"execution":{"iopub.status.busy":"2023-09-04T10:39:59.161786Z","iopub.execute_input":"2023-09-04T10:39:59.162218Z","iopub.status.idle":"2023-09-04T10:39:59.180039Z","shell.execute_reply.started":"2023-09-04T10:39:59.162177Z","shell.execute_reply":"2023-09-04T10:39:59.178835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_path = 'YOURPATH'\nresults_path = images_path+'_results'\npresplit = False\ntrain_split = 0.5\nval_split = 0.25\ntest_split = 0.25\nbatch_size = 128\nthreads = 0\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntraining_set_loader, testing_set_loader, validation_set_loader, dataset, training_set, testing_set, validation_set = \\\n                  load_transform_images(images_path, presplit, train_split, test_split, val_split, batch_size, threads, mean, std)\n\nclass_names = dataset.classes\nclass_names = [classes[10:] for classes in class_names]\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T10:39:59.181724Z","iopub.execute_input":"2023-09-04T10:39:59.182352Z","iopub.status.idle":"2023-09-04T10:40:08.365530Z","shell.execute_reply.started":"2023-09-04T10:39:59.182312Z","shell.execute_reply":"2023-09-04T10:40:08.364566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net_model = resnet.resnet152(pretrained=True)\nnet_name = 'resnet152'\nunfrozen_layers = ['layer4', 'fc'] \n\ndropout_ratio = 0.9\n\nnet_model = load_network(net_model, net_name, dropout_ratio, class_names, unfrozen_layers)\n\nprint(f'Images in training set {len(training_set)}, validation set {len(validation_set)}, testing set {len(testing_set)}')","metadata":{"execution":{"iopub.status.busy":"2023-09-04T10:40:10.303228Z","iopub.execute_input":"2023-09-04T10:40:10.303572Z","iopub.status.idle":"2023-09-04T10:40:16.293522Z","shell.execute_reply.started":"2023-09-04T10:40:10.303538Z","shell.execute_reply":"2023-09-04T10:40:16.292467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.0001\nepochs = 100\nmomentum = 0.9\nweight_decay = 0\npatience = 3\nn_epochs_stop = 5\n\nnet_model, loss_acc, y_testing, preds = train_model(results_path, net_name, net_model, training_set_loader, validation_set_loader, \n                                                    learning_rate, epochs, momentum, weight_decay, patience, n_epochs_stop)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T10:40:19.431413Z","iopub.execute_input":"2023-09-04T10:40:19.431961Z","iopub.status.idle":"2023-09-04T12:25:10.081085Z","shell.execute_reply.started":"2023-09-04T10:40:19.431921Z","shell.execute_reply":"2023-09-04T12:25:10.080156Z"},"trusted":true},"execution_count":null,"outputs":[]}]}